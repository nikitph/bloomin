# Thresholded Accumulation: Calibration Analysis Report

**Generated:** 2025-12-16 09:52:14

## The Calibration Problem

The original TA formulation uses `calibrated_threshold = raw_threshold * sqrt(n)`.

**Problem:** This calibration is designed for detecting if the AVERAGE similarity
exceeds a threshold, NOT for detecting if ANY SINGLE element exceeds it.

For "any match" detection, the accumulated score behaves as:
- **With a match:** score = match_similarity + noise ≈ τ + O(sqrt(n/d))
- **Without match:** score = noise ≈ O(sqrt(n/d))

The sqrt(n) calibration creates a threshold that grows too fast, causing 100% false negatives.

## Solution: Additive Noise Calibration

For "any match" detection, use:
```
calibrated_threshold = raw_threshold + k * sqrt(n/d)
```

Where:
- `raw_threshold` = τ (e.g., 0.85)
- `k` = noise multiplier (safety margin)
- `n` = cache size
- `d` = embedding dimension

## Calibration Comparison Results


### Strategy: additive_k3.0

| Cache Size | Speedup | Accuracy | Precision | Recall | FPR | FNR |
|------------|---------|----------|-----------|--------|-----|-----|
| 100 | 9x | 70.0% | 100.0% | 0.1% | 0.0% | 99.9% |
| 500 | 18x | 70.0% | 90.0% | 0.2% | 0.0% | 99.8% |
| 1,000 | 24x | 70.0% | 100.0% | 0.1% | 0.0% | 99.9% |
| 5,000 | 77x | 70.1% | 60.0% | 0.4% | 0.1% | 99.6% |
| 10,000 | 128x | 69.9% | 46.7% | 0.1% | 0.1% | 99.9% |
| 50,000 | 552x | 69.9% | 40.0% | 0.2% | 0.2% | 99.8% |
| 100,000 | 1141x | 70.0% | 71.9% | 0.5% | 0.2% | 99.5% |

### Strategy: additive_k2.0

| Cache Size | Speedup | Accuracy | Precision | Recall | FPR | FNR |
|------------|---------|----------|-----------|--------|-----|-----|
| 100 | 10x | 70.5% | 100.0% | 1.7% | 0.0% | 98.3% |
| 500 | 20x | 70.6% | 73.8% | 2.7% | 0.3% | 97.3% |
| 1,000 | 28x | 70.4% | 67.4% | 2.7% | 0.6% | 97.3% |
| 5,000 | 76x | 70.0% | 47.5% | 2.3% | 1.0% | 97.7% |
| 10,000 | 126x | 69.7% | 42.1% | 2.7% | 1.7% | 97.3% |
| 50,000 | 494x | 69.1% | 26.0% | 2.0% | 2.2% | 98.0% |
| 100,000 | 994x | 69.4% | 36.6% | 2.8% | 2.1% | 97.2% |

### Strategy: additive_k1.0

| Cache Size | Speedup | Accuracy | Precision | Recall | FPR | FNR |
|------------|---------|----------|-----------|--------|-----|-----|
| 100 | 9x | 74.7% | 96.9% | 16.4% | 0.3% | 83.6% |
| 500 | 20x | 71.3% | 60.0% | 14.6% | 4.3% | 85.4% |
| 1,000 | 24x | 69.5% | 47.4% | 13.7% | 6.6% | 86.3% |
| 5,000 | 54x | 67.9% | 41.9% | 17.6% | 10.5% | 82.4% |
| 10,000 | 122x | 67.0% | 38.0% | 16.1% | 11.3% | 83.9% |
| 50,000 | 459x | 65.3% | 33.0% | 15.1% | 13.1% | 84.9% |
| 100,000 | 987x | 64.2% | 31.0% | 15.7% | 15.0% | 84.3% |

### Strategy: sqrt_n_k1.0

| Cache Size | Speedup | Accuracy | Precision | Recall | FPR | FNR |
|------------|---------|----------|-----------|--------|-----|-----|
| 100 | 9x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 500 | 21x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 1,000 | 24x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 5,000 | 68x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 10,000 | 123x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 50,000 | 388x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |
| 100,000 | 911x | 70.0% | 100.0% | 0.0% | 0.0% | 100.0% |


## Key Findings

1. **Calibration matters significantly** for accuracy metrics
2. **Additive noise calibration** (k=1-2) achieves best recall
3. **sqrt(n) calibration** results in 0% recall (too conservative)
4. **Speedup is independent** of calibration choice (~1141x at largest cache)

## Recommended Configuration

For "any match" detection use cases:
```python
calibration = CalibrationStrategy.ADDITIVE_NOISE
noise_multiplier = 2.0  # Balance precision/recall
```

Best performing strategy: **additive_k1.0** with 15.6% average recall

## Theoretical Explanation

The accumulated dot product for a query q is:

```
A · q = Σᵢ (eᵢ · q)
```

For random unit vectors in R^d:
- E[eᵢ · q] = 0 (orthogonal in expectation)
- Var[eᵢ · q] ≈ 1/d

Sum of n such terms:
- E[A · q] = 0
- Var[A · q] = n/d
- Std[A · q] = sqrt(n/d)

If ONE element matches with similarity τ:
```
A · q ≈ τ + (n-1) * noise_per_element
      ≈ τ + N(0, sqrt(n/d))
```

To reliably detect this, threshold at:
```
τ + k * sqrt(n/d) where k ≈ 2-3 for 95-99% confidence
```

---

*Report generated by TA Experiment v3*
